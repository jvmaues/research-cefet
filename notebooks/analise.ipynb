{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1d09750-b602-4810-99f5-3820f580d2b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Descrição do Notebook\n",
    "\n",
    "Projeto com a ideia de analises o impacto de diferentes centralidade no algoritmo Cuthill McKee\n",
    "\n",
    "## Algoritmos Base: Cuthill McKee e Reverse Cuthill McKee\n",
    "\n",
    "## Utilizada também a lib NetworkX de python\n",
    "\n",
    "## Centralidade utilizadas:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2cc2f3-50e3-4def-98a6-a14c968759c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports do projeto\n",
    "\n",
    "#### Import to read the files dict \n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os import error\n",
    "\n",
    "import datetime\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "\n",
    "import math\n",
    "import csv\n",
    "\n",
    "### Import to run the graph lib\n",
    "import networkx as nx\n",
    "from networkx.utils import cuthill_mckee_ordering\n",
    "from networkx.utils import reverse_cuthill_mckee_ordering\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e241a38b-03d3-4d8b-a425-ad4ce7de6a61",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15cba8c-ecf7-4d95-8dc6-e7875468e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### measure bandwidth  ########\n",
    "\n",
    "mypath = \"...\"\n",
    "\n",
    "# list_path = rf.readFilesInDict(mypath, '.mtx')\n",
    "\n",
    "A = [[1,4], [0,2,4], [1,3], [2,4,5], [0,1,3], [3]]\n",
    "f1 = [2, 3, 4, 1, 5, 6]\n",
    "\n",
    "B = [[1], [0, 2, 3], [1], [1, 4], [3]]\n",
    "f2 = [3, 1, 2, 5, 4]\n",
    "\n",
    "def dif(p, q):\n",
    "    return abs(p-q)\n",
    "        \n",
    "def measureBand_old(A, f):\n",
    "    width = 0\n",
    "    for v in range(len(A)):\n",
    "        for adj in A[v]:\n",
    "            temp = dif(f[v], f[adj])\n",
    "            if temp > width:\n",
    "                width = temp\n",
    "            \n",
    "    return width\n",
    "\n",
    "###### measure bandwidth  ########\n",
    "\n",
    "def labels(R):\n",
    "    f = defaultdict(int)\n",
    "    label = 1\n",
    "    for node in R:\n",
    "        f[node] = label\n",
    "        label=label+1\n",
    "    return f\n",
    "\n",
    "\n",
    "def measureBand(adj_dict, F):\n",
    "    width = 0\n",
    "    for key in adj_dict:\n",
    "        for node in adj_dict[key]:\n",
    "            temp = abs(F[key] - F[node])\n",
    "            if temp > width:\n",
    "                width = temp\n",
    "            \n",
    "    return width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "856671f7-c927-48e5-9b8c-cf0d49a537b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Function to read the files dict ####\n",
    "\n",
    "def readFilesInDict(path, extension):\n",
    "    onlymtxComp = [os.path.join(path, file) for file in os.listdir(path) if file.endswith(extension)]\n",
    "    return onlymtxComp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "957641e7-e103-447e-a092-84dedb355808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### function to read the instance and data struct ####\n",
    "\n",
    "def load_instance(filename):\n",
    "    edges = []\n",
    "    neighbours = defaultdict(list)\n",
    "    neigh = defaultdict(list)\n",
    "    flag = True\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "\n",
    "        if flag == True:\n",
    "            nnodes, nedges = [int(x) for x in line.split()]\n",
    "            flag = False\n",
    "        else:\n",
    "            e1, e2 = [int(x) for x in line.split()]\n",
    "\n",
    "            neigh[e1].append(e2)\n",
    "            if e1 != e2:\n",
    "                edges.append((min(e1, e2), max(e1, e2)))\n",
    "                neighbours[e1].append(e2)\n",
    "                neighbours[e2].append(e1)\n",
    "            else:\n",
    "                nedges = nedges - 1\n",
    "    f.close()\n",
    "\n",
    "    f = []\n",
    "    \n",
    "    for v in neighbours:\n",
    "        f.append(v)\n",
    "\n",
    "    nodes = []\n",
    "\n",
    "    for v in neighbours:\n",
    "        nodes.append(v)\n",
    "\n",
    "    lista_adj = []\n",
    "\n",
    "    for n in nodes:\n",
    "        lista_adj.append(neighbours[n])\n",
    "\n",
    "    matrix = []\n",
    "\n",
    "    for key in neighbours:\n",
    "        line = [0]*nnodes\n",
    "        for element in neighbours[key]:\n",
    "            line[element-1] = 1\n",
    "        matrix.append(line)\n",
    "    \n",
    "    return nnodes, nedges, edges, neighbours, lista_adj, matrix\n",
    "\n",
    "def print_instance(qtd_nodes, qtd_edges, edges, neighbours):\n",
    "    print(str(qtd_nodes)+\" \"+str(qtd_edges))\n",
    "\n",
    "    for e in edges:\n",
    "        print(str(e[0])+\" \"+str(e[1]))\n",
    "\n",
    "    for i in neighbours:\n",
    "        print(neighbours[i])\n",
    "\n",
    "    print(neighbours)\n",
    "\n",
    "# nome_arquivo = \"/home/joaovitor/Documents/TCC/research-cefet/bandwidth-reduction/data/494_bus.mtx\"\n",
    "\n",
    "# nnodes, nedges, edges, neighbours, lista_adj, matrix = load_instance(nome_arquivo)\n",
    "# f = [None]*len(neighbours)\n",
    "\n",
    "# for line in range(len(matrix)):\n",
    "#     print(matrix[line])\n",
    "\n",
    "# print(\"nnodes: \",nnodes)\n",
    "# print(\"nedges: \",nedges)\n",
    "# print(\"edges: \",edges) \n",
    "# print(\"neighbours: \",neighbours)\n",
    "# print(\"lista_adj: \",lista_adj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1b0ff6-d1fa-42d9-a385-1d3e22197e2e",
   "metadata": {},
   "source": [
    "## Extracting DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc57016f-362c-474f-b621-e747c362a323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c5bf998-9d01-49cb-aa38-068835a22f28",
   "metadata": {},
   "source": [
    "## Handling with lib NetworkX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e99779e-10e0-4be2-9062-870409690c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HEURISTIC SETTING\n",
    "\n",
    "# HEURISTIC BIGGEST DEGREE\n",
    "def biggest_degree(G):\n",
    "    return max(G, key=G.degree)\n",
    "\n",
    "# HEURISTIC SMALLEST DEGREE\n",
    "def smallest_degree(G):\n",
    "    return min(G, key=G.degree)\n",
    "\n",
    "\n",
    "# HEURISTIC BIGGEST EIGENVECTOR\n",
    "def smallest_eigenvector(G):\n",
    "    centrality = nx.eigenvector_centrality(G, max_iter=600)\n",
    "    return max(centrality, key=centrality.get)\n",
    "\n",
    "# HEURISTIC SMALLEST EIGENVECTOR\n",
    "def biggest_eigenvector(G):\n",
    "    centrality = nx.eigenvector_centrality(G, max_iter=600)\n",
    "    return min(centrality, key=centrality.get)\n",
    "\n",
    "# HEURISTIC BIGGEST KATZ\n",
    "def biggest_katz(G):\n",
    "    centrality = nx.katz_centrality(G, max_iter=10000)\n",
    "    return max(centrality, key=centrality.get)\n",
    "\n",
    "# HEURISTIC SMALLEST KATZ\n",
    "def smallest_katz(G):\n",
    "    centrality = nx.katz_centrality(G, max_iter=10000)\n",
    "    return min(centrality, key=centrality.get)\n",
    "\n",
    "# HEURISTIC BIGGEST CLOSENESS\n",
    "def biggest_closeness(G):\n",
    "    centrality = nx.closeness_centrality(G)\n",
    "    return max(centrality, key=centrality.get)\n",
    "\n",
    "# HEURISTIC SMALLEST CLOSENESS\n",
    "def smallest_closeness(G):\n",
    "    centrality = nx.closeness_centrality(G)\n",
    "    return min(centrality, key=centrality.get)\n",
    "\n",
    "# HEURISTIC BIGGEST HARMONIC\n",
    "def biggest_harmonic(G):\n",
    "    centrality = nx.harmonic_centrality(G)\n",
    "    return max(centrality, key=centrality.get)\n",
    "\n",
    "# HEURISTIC SMALLEST HARMONIC\n",
    "def smallest_harmonic(G):\n",
    "    centrality = nx.harmonic_centrality(G)\n",
    "    return min(centrality, key=centrality.get)\n",
    "\n",
    "#HEURISTIC BIGGEST BETWEENNESS\n",
    "def biggest_betweenness(G):\n",
    "    centrality = nx.betweenness_centrality(G)\n",
    "    return max(centrality, key=centrality.get)\n",
    "\n",
    "# HEURISTIC SMALLEST BETWEENNESS\n",
    "def smallest_betweenness(G):\n",
    "    centrality = nx.betweenness_centrality(G)\n",
    "    return min(centrality, key=centrality.get)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FUNCTION TO GET BANDWIDTH \n",
    "def bandwidth(G):\n",
    "    '''Calculate the bandwidth'''\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    x, y = np.nonzero(A)\n",
    "    \n",
    "    w = (y - x).max() + (x - y).max() + 1\n",
    "    return w\n",
    "\n",
    "#INIT A GRAPH\n",
    "def init_graph(edges):\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(edges)\n",
    "    return G\n",
    "\n",
    "# BANDWIDTH CUTHILL MCKEE\n",
    "def cuthill(G, heuristic):\n",
    "    rcm = list(cuthill_mckee_ordering(G, heuristic=heuristic))\n",
    "    adj_matrix = nx.adjacency_matrix(G, nodelist=rcm)\n",
    "    x, y = np.nonzero(adj_matrix)\n",
    "    return (y - x).max() + (x - y).max() + 1\n",
    "\n",
    "# BANDWIDTH REVERSE CUTHILL MCKEE\n",
    "def reverse_cuthill(G, heuristic):\n",
    "    rcm = list(reverse_cuthill_mckee_ordering(G, heuristic=heuristic))\n",
    "    adj_matrix = nx.adjacency_matrix(G, nodelist=rcm)\n",
    "    x, y = np.nonzero(adj_matrix)\n",
    "    return (y - x).max() + (x - y).max() + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "743565e6-e4e1-4383-87f6-16a882b90fdc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/joaovitor/Documents/Pesquisa/research-cefet/notebooks/analise.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/joaovitor/Documents/Pesquisa/research-cefet/notebooks/analise.ipynb#ch0000010?line=0'>1</a>\u001b[0m nnodes, nedges, edges, neighbours, lista_adj, matrix \u001b[39m=\u001b[39m load_instance(list_path[\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joaovitor/Documents/Pesquisa/research-cefet/notebooks/analise.ipynb#ch0000010?line=2'>3</a>\u001b[0m A \u001b[39m=\u001b[39m init_graph(edges)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joaovitor/Documents/Pesquisa/research-cefet/notebooks/analise.ipynb#ch0000010?line=4'>5</a>\u001b[0m \u001b[39m# w2 = cuthill(G, biggest_closeness)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joaovitor/Documents/Pesquisa/research-cefet/notebooks/analise.ipynb#ch0000010?line=5'>6</a>\u001b[0m \u001b[39m# print(f\"low bandwidth cuthill: {w2}\")\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joaovitor/Documents/Pesquisa/research-cefet/notebooks/analise.ipynb#ch0000010?line=6'>7</a>\u001b[0m     \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joaovitor/Documents/Pesquisa/research-cefet/notebooks/analise.ipynb#ch0000010?line=10'>11</a>\u001b[0m \u001b[39m# w4 = cuthill(G, smallest_katz)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joaovitor/Documents/Pesquisa/research-cefet/notebooks/analise.ipynb#ch0000010?line=11'>12</a>\u001b[0m \u001b[39m# print(f\"low bandwidth cuthill: {w2}\")\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'list_path' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nnodes, nedges, edges, neighbours, lista_adj, matrix = load_instance(list_path[0])\n",
    "\n",
    "A = init_graph(edges)\n",
    "\n",
    "# w2 = cuthill(G, biggest_closeness)\n",
    "# print(f\"low bandwidth cuthill: {w2}\")\n",
    "    \n",
    "# w3 = cuthill(G, smallest_closeness)\n",
    "# print(f\"low bandwidth reverse cuthill: {w3}\")\n",
    "\n",
    "# w4 = cuthill(G, smallest_katz)\n",
    "# print(f\"low bandwidth cuthill: {w2}\")\n",
    "    \n",
    "w5 = cuthill(A, biggest_katz)\n",
    "print(f\"low bandwidth reverse cuthill: {w3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aa4c56-e405-446e-a70c-db320064903b",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656baab-887f-41db-86f5-25077a690cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Main cell that call the tested algorithms\n",
    "\n",
    "main_path = \"../data\"\n",
    "list_path = readFilesInDict(main_path, \".mtx\")\n",
    "\n",
    "heuristics = [ biggest_degree, smallest_degree, smallest_eigenvector, biggest_eigenvector, biggest_katz, smallest_katz,\n",
    "                     biggest_closeness, smallest_closeness, biggest_harmonic, smallest_harmonic, biggest_betweenness, smallest_betweenness ]\n",
    "\n",
    "with open('resultados.csv', mode='a+') as csv_file:\n",
    "\n",
    "    fieldnames = ['instance','timestamp', 'original_band', 'biggest_degree', 'smallest_degree', 'smallest_eigenvector', 'biggest_eigenvector', 'biggest_katz', 'smallest_katz',\n",
    "                     'biggest_closeness', 'smallest_closeness', 'biggest_harmonic', 'smallest_harmonic', 'biggest_betweenness', 'smallest_betweenness' ]\n",
    "\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    \n",
    "    \n",
    "\n",
    "    for instance_path in list_path:\n",
    "        \n",
    "\n",
    "            instance_name = instance_path.replace(main_path, \"\").replace(\"/\", \"\").replace(\".mtx\", \"\")\n",
    "\n",
    "            nnodes, nedges, edges, neighbours, lista_adj, matrix = load_instance(instance_path)\n",
    "            \n",
    "            print(\"#########################\", instance_name ,\"############################\")\n",
    "            \n",
    "            #initial vars\n",
    "            solutions = []\n",
    "            G = init_graph(edges)\n",
    "            original_w = bandwidth(G)\n",
    "            \n",
    "            \n",
    "            heuristics_name = [ 'biggest_degree', 'smallest_degree', 'biggest_eigenvector', 'smallest_eigenvector','biggest_katz', 'smallest_katz',\n",
    "                               'biggest_closeness', 'smallest_closeness', 'biggest_harmonic', 'smallest_harmonic','biggest_betweenness', 'smallest_betweenness' ]\n",
    "            \n",
    "            solutions.append(original_w)\n",
    "            print(instance_name)\n",
    "            \n",
    "    \n",
    "            for h in heuristics:\n",
    "                \n",
    "                #w_cm = cuthill(G, h)\n",
    "                #print(f\"low bandwidth cuthill: {w_rcm}\")\n",
    "                \n",
    "                try:\n",
    "                    w_rcm = reverse_cuthill(G, h)\n",
    "                    solutions.append(w_rcm)\n",
    "                except:\n",
    "                    solutions.append(\"error\")\n",
    "                \n",
    "\n",
    "            \n",
    "\n",
    "            writer.writerow({'instance': instance_name,\n",
    "                             'timestamp': datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),\n",
    "                             'original_band': solutions[0],\n",
    "                             'biggest_degree': solutions[1],\n",
    "                             'smallest_degree': solutions[2],\n",
    "                             'biggest_eigenvector': solutions[3],\n",
    "                             'smallest_eigenvector': solutions[4],\n",
    "                             'biggest_katz': solutions[5],\n",
    "                             'smallest_katz': solutions[6],\n",
    "                             'biggest_closeness': solutions[7],\n",
    "                             'smallest_closeness': solutions[8],\n",
    "                             'biggest_harmonic': solutions[9],\n",
    "                             'smallest_harmonic': solutions[10],\n",
    "                             'biggest_betweenness': solutions[11],\n",
    "                             'smallest_betweenness': solutions[12]\n",
    "                            })\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a222b3b-33a1-462c-83a3-e9646537461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('resultados.csv', mode='a+') as csv_file:\n",
    "\n",
    "    fieldnames = ['instance','timestamp', 'constructive', 'constructive random',  'cuchill mckee', 'reverse cuchill mckee' ]\n",
    "\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    \n",
    "   \n",
    "\n",
    "    for instance_path in list_path:\n",
    "\n",
    "        instance_name = instance_path.replace(mypath, \"\").replace(\"/\", \"\").replace(\".mtx\", \"\")\n",
    "\n",
    "        nnodes, nedges, edges, neighbours, lista_adj, matrix = ri.load_instance(instance_path)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        writer.writerow({'instance': instance_name,\n",
    "                         'timestamp': datetime.datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),\n",
    "                         'constructive': w1,\n",
    "                         'constructive random': w2,\n",
    "                         'cuchill mckee': w3,\n",
    "                         'reverse cuchill mckee': w4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d05f906",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "Failed to start the Kernel 'Python 3.8.10 64-bit'. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Kernel has not been started"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "#data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# análise de correlação\n",
    "correlation = data.corr()\n",
    "\n",
    "# plot da matriz de correlação\n",
    "\n",
    "plot = sn.heatmap(correlation, annot = True, fmt=\".1f\", linewidths=.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2ad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
